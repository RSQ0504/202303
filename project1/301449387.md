#                               			Project1 - Report

### 																	Rongsheng Qian

### 																		301449387

## Q 1.1 Inner Product Layer

![Inner Product Test](/Users/davidqian/Desktop/CMPT 412/Project/project1/results/Inner Product Test.png)

## Q 1.2 Pooling Layer

![Pooling Test](/Users/davidqian/Desktop/CMPT 412/Project/project1/results/Pooling Test.png)

## Q 1.3 Convolution Layer

![Convolution Test 1](/Users/davidqian/Desktop/CMPT 412/Project/project1/results/Convolution Test 1.png)

![Convolution Test 2](/Users/davidqian/Desktop/CMPT 412/Project/project1/results/Convolution Test 2.png)

## Q 1.4 ReLU

### Problem I meet:

When I am running train_lenet to train my network there will report a warning:

"RuntimeWarning: divide by zero encountered in log nll = -np.sum(np.log(P[I == 1]))‚Äù

### Solution:

I think there is sth wrong caused by copying pointer in relu forward. I don't know how to fix it so i just implemented it in another way. Then the network worked and accuracy reached 95. I have tried np.maximum() function. It works for me. (My original method is out = in; out[out<0]=0 which returns error)

## Q 2.1 ReLU

### Problem I meet:

### Solution:

## Q 2.2 Inner Product layer

### Problem I meet:

### Solution:

## Q 3.1 Training

0
test accuracy: 0.104

500
test accuracy: 0.954

1000
test accuracy: 0.948

1500
test accuracy: 0.952 

2000
test accuracy: 0.956

## Q 3.2 Test the network

[[46.  0.  0.  0.  0.  0.  1.  0.  0.  0.]
 [ 0. 46.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0. 49.  1.  0.  0.  0.  1.  2.  0.]
 [ 1.  0.  1. 47.  0.  1.  0.  0.  1.  0.]
 [ 0.  0.  0.  0. 51.  0.  0.  1.  0.  3.]
 [ 0.  0.  0.  0.  0. 44.  1.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0. 45.  0.  1.  0.]
 [ 0.  1.  2.  0.  0.  0.  0. 45.  1.  2.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 45.  1.]
 [ 0.  0.  0.  0.  0.  0.  1.  0.  0. 58.]]

<img src="/Users/davidqian/Desktop/CMPT 412/Project/project1/cm.png" alt="cm" style="zoom: 67%;" />

              precision    recall  f1-score   support
    
         0.0       0.82      1.00      0.90         9
         1.0       1.00      1.00      1.00        11
         2.0       0.92      1.00      0.96        11
         3.0       1.00      0.75      0.86         8
         4.0       1.00      1.00      1.00         7
         5.0       0.86      1.00      0.92         6
         6.0       1.00      0.91      0.95        11
         7.0       1.00      0.71      0.83         7
         8.0       1.00      0.94      0.97        18
         9.0       0.86      1.00      0.92        12
    
    accuracy                           0.94       100
     macro avg       0.94      0.93      0.93       100
    weighted avg     0.95      0.94      0.94       100
## Q 3.3 Real-world testing

![1](/Users/davidqian/Desktop/CMPT 412/Project/project1/python/3.3image/1.png)

![2](/Users/davidqian/Desktop/CMPT 412/Project/project1/python/3.3image/2.png)

![3](/Users/davidqian/Desktop/CMPT 412/Project/project1/python/3.3image/3.png)

![4](/Users/davidqian/Desktop/CMPT 412/Project/project1/python/3.3image/4.png)

![5](/Users/davidqian/Desktop/CMPT 412/Project/project1/python/3.3image/5.png)

predict: [2]; label: 2
predict: [9]; label: 9
predict: [4]; label: 4
predict: [0]; label: 0
predict: [7]; label: 7

## Part 4 Visualization

## Q 4.1 

<img src="/Users/davidqian/Desktop/CMPT 412/Project/project1/img.png" alt="img" style="zoom:50%;" />

<img src="/Users/davidqian/Desktop/CMPT 412/Project/project1/conv_feature.png" alt="conv_feature" style="zoom: 33%;" />

<img src="/Users/davidqian/Desktop/CMPT 412/Project/project1/relu_feature.png" alt="relu_feature" style="zoom: 33%;" />

## Q 4.2 Compare

